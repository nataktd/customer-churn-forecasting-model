# Отток клиентов банка
# Описание проекта:
Нам предоставлены данные Из «Бета-Банка» о поведении клиентов и расторжении договоров с банком.
Банк обеспокоин тем, что стали уходить клиенты.Отток клиентов не значительный, но заметный.

Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

# Цель:
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет.
Для этого необходимо постоить модель с предельно большим значением F1-меры (до 0.59).
Проверить F1-меру на тестовой выборке.

Дополнительно будем измеряйть AUC-ROC, сравнивайть её значение с F1-мерой .

# План работы

1  Изучение данных

2  Предобработка данных

3  Разделение данных датафрейма на выборки : обучающая, валидационная и тестовая.

4  Выбор модели

4.1  Алгоритм машинного обучения - Дерево Решений. Decision Tree

4.2  Алгоритм машинного обучения - Случайный Лес. Random Forest

4.3  Алгоритм машинного обучения - Логистическая регрессия. Logistic Regression

4.4  ROC-кривая для каждой модели. Показатель AUC-ROC

4.5  Масштабирование признаков.

4.5.1  Алгоритм машинного обучения - Дерево Решений. Decision Tree

4.5.2  Алгоритм машинного обучения - Случайный Лес. Random Forest

4.5.3  Алгоритм машинного обучения - Логистическая регрессия. Logistic Regression

5  Дисбаланс классов. Пути решения проблемы. Поиск лучшей модели.

5.1  Взвешивание классов.

5.1.1  Алгоритм машинного обучения - Дерево Решений. Decision Tree

5.1.1.1  Не масштабированные данные

5.1.1.2  Масштабированные данные

5.1.2  Алгоритм машинного обучения - Случайный Лес. Random Forest

5.1.2.1  Не масштабированные данные

5.1.2.2  Масштабированные данные

5.1.3  Алгоритм машинного обучения - Логистическая регрессия. Logistic Regression

5.1.3.1  Не масштабированные данные

5.1.3.2  Масштабированные данные

5.2  Метод downsampling

5.2.1  Алгоритм машинного обучения - Дерево Решений. Decision Tree

5.2.1.1  Не масштабированные данные

5.2.1.2  Масштабированные данные

5.2.2  Алгоритм машинного обучения - Случайный Лес. Random Forest

5.2.2.1  Не масштабированные данные

5.2.2.2  Масштабированные данные

5.2.3  Алгоритм машинного обучения - Логистическая регрессия. Logistic Regression

5.2.3.1  Не масштабированные данные

5.2.3.2  Масштабированные данные

5.3  Метод upsampling

5.3.1  Алгоритм машинного обучения - Дерево Решений. Decision Tree

5.3.1.1  Не масштабированные данные

5.3.1.2  Масштабированные данные

5.3.2  Алгоритм машинного обучения - Случайный Лес. Random Forest

5.3.2.1  Не масштабированные данные

5.3.2.2  Масштабированные данные

5.3.3  Алгоритм машинного обучения - Логистическая регрессия. Logistic Regression

5.3.3.1  Не масштабированные данные

5.3.3.2  Масштабированные данные

5.4  Вывод по разделу

6  Проверка моделей на тестовой выборке.

7  Итоги и выводы по проекту

# Итоги

Поставленного в задании результата достигли на моделе Случайный Лес при увеличении выборки (масштабированние данных на результат не повлияло) метрика F1- мера = 0.5934, метрика AUC-ROC = 0.8290. Смущал только низкий результат метрики recall (0.5310), значит модель предсказывает только 53.1% всех объектов класса 1 целевой переменной.

Модель Дерево решений (на увеличенной выборке и масштабированных данных) показывает метрику F1- мера = 0.5661 (ниже, чем нам нужно), при этом высокий recall (0.7332) - выше, чем у отобранной нами лучшей модели.

Если сравнивать модели, у которых метрика recall выше, чем у лучшей модели, то брасается в глаза следующий факт: у всех этих моделей метрика accuracy ниже чем средняя точность dummy (0.796) определенная классификатором DummyClassifier. Можно предположить, что модели ни чего не предсказывают, а просто пересчитывает классы, а значит мы подобрали оптимальную модель.